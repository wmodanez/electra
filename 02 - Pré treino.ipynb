{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "suspected-booking",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Instalando a versÃ£o mais nova do transformers direto da master\n",
    "# !pip install git+https://github.com/huggingface/transformers\n",
    "# !pip install datasets\n",
    "!pip list | grep -E 'transformers|tokenizers'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "elementary-ukraine",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from transformers import ElectraTokenizerFast\n",
    "from tokenizers.processors import BertProcessing\n",
    "from tokenizers import ByteLevelBPETokenizer, BertWordPieceTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "combined-wallet",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = BertWordPieceTokenizer(\n",
    "    unk_token='[UNK]',\n",
    "    sep_token='[SEP]',\n",
    "    cls_token='[CLS]',\n",
    "    pad_token='[PAD]',\n",
    "    mask_token='[MASK]',\n",
    "    clean_text=False,\n",
    "    handle_chinese_chars=False,\n",
    "    strip_accents=False,\n",
    "    lowercase=True\n",
    ")\n",
    "\n",
    "# tokenizer = ByteLevelBPETokenizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "mathematical-trance",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.train(\n",
    "    files=['data/texto-sm.txt'],\n",
    "    vocab_size=52000,\n",
    "    min_frequency=3,\n",
    "    limit_alphabet=1000,\n",
    "#     special_tokens=['[PAD]', '[UNK]', '[CLS]', '[MASK]', '[SEP]'],\n",
    "    wordpieces_prefix='##',\n",
    "    show_progress=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "quick-potential",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['sou', 'da', 'paz', '!']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.encode('Sou da paz!').tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "welsh-vehicle",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer._tokenizer.post_processor = BertProcessing(\n",
    "    ('[SEP]', tokenizer.token_to_id('[SEP]')),\n",
    "    ('[CLS]', tokenizer.token_to_id('[CLS]')),\n",
    ")\n",
    "tokenizer.enable_truncation(max_length=512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "nervous-johnson",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['[CLS]', 'sou', 'da', 'paz', '!', '[SEP]']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.encode('Sou da paz!').tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "agreed-difference",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['content/electranez-vocab.txt']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token_dir = 'content'\n",
    "if not os.path.exists(token_dir):\n",
    "  os.makedirs(token_dir)\n",
    "tokenizer.save_model(token_dir, 'electranez')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "advised-immunology",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default-f88fa38aaf68c077\n",
      "Reusing dataset csv (/home/modanez/.cache/huggingface/datasets/csv/default-f88fa38aaf68c077/0.0.0/965b6429be0fc05f975b608ce64e1fa941cc8fb4f30629b523d2390f3c0e1a93)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['text'],\n",
      "        num_rows: 528352\n",
      "    })\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "%timeit\n",
    "\n",
    "from datasets import load_dataset\n",
    "dataset = load_dataset('csv', data_files={'train':['data/texto-sm.csv']})\n",
    "print(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "piano-springfield",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We will use the GPU: GeForce GTX 1070\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "if torch.cuda.is_available():  \n",
    "    device = torch.device(\"cuda\")\n",
    "    print('We will use the GPU:', torch.cuda.get_device_name(0))\n",
    "else:\n",
    "    print('No GPU available, using the CPU instead.')\n",
    "    device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "demonstrated-binary",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import ElectraTokenizer, ElectraTokenizerFast\n",
    "\n",
    "electra_tokenizer = ElectraTokenizerFast(\n",
    "    vocab_file='content/electranez-vocab.txt', \n",
    "    do_lower_case=True, \n",
    "    do_basic_tokenize=True, \n",
    "    never_split=None, \n",
    "    unk_token='[UNK]', \n",
    "    sep_token='[SEP]', \n",
    "    pad_token='[PAD]', \n",
    "    cls_token='[CLS]', \n",
    "    mask_token='[MASK]', \n",
    "    max_length=512, \n",
    "    tokenize_chinese_chars=False, \n",
    "    strip_accents=False,\n",
    "    name='electranez-base'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "choice-phase",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('electranez/tokenizer_config.json',\n",
       " 'electranez/special_tokens_map.json',\n",
       " 'electranez/vocab.txt',\n",
       " 'electranez/added_tokens.json')"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# electra_tokenizer.save_vocabulary('electranez/')\n",
    "electra_tokenizer.save_pretrained('electranez/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "expected-invasion",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import ElectraConfig, ElectraModel\n",
    "\n",
    "configuration = ElectraConfig(\n",
    "    vocab_size=52000,\n",
    "    embedding_size=128,\n",
    "    hidden_size=256,    \n",
    "    num_hidden_layers=12,\n",
    "    num_attention_heads=4,\n",
    "    intermediate_size=1024,\n",
    "    hidden_act='gelu',\n",
    "    hidden_dropout_prob=0.1,\n",
    "    attention_probs_dropout_prob=0.1,\n",
    "    max_position_embeddings=512,\n",
    "    type_vocab_size=2,\n",
    "    initializer_range=0.02,\n",
    "    layer_norm_eps=1e-12,\n",
    "    summary_type='first',\n",
    "    summary_use_proj=True,\n",
    "    summary_activation='gelu',\n",
    "    summary_last_dropout=0.1,\n",
    "    position_embedding_type='absolute',\n",
    ")\n",
    "\n",
    "model = ElectraModel(configuration)\n",
    "configuration = model.config\n",
    "\n",
    "# electra_tokenizer = ElectraTokenizer.from_pretrained('electranez/', max_length=512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "rotary-grove",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For the discriminator, ElectraForPreTraining was used.\n",
    "# For the generator, ElectraForMaskedLM was used.\n",
    "\n",
    "from transformers import ElectraForMaskedLM, ElectraForPreTraining\n",
    "\n",
    "discrimator = ElectraForPreTraining(config=configuration)\n",
    "generator = ElectraForMaskedLM(config=configuration)\n",
    "\n",
    "print(discrimator.num_parameters())\n",
    "print(generator.num_parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "decimal-conditions",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "file electranez/config.json not found\n"
     ]
    },
    {
     "ename": "OSError",
     "evalue": "Can't load config for 'electranez/'. Make sure that:\n\n- 'electranez/' is a correct model identifier listed on 'https://huggingface.co/models'\n\n- or 'electranez/' is the correct path to a directory containing a config.json file\n\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda3/envs/transformer/lib/python3.6/site-packages/transformers/configuration_utils.py\u001b[0m in \u001b[0;36mget_config_dict\u001b[0;34m(cls, pretrained_model_name_or_path, **kwargs)\u001b[0m\n\u001b[1;32m    430\u001b[0m                 \u001b[0mlocal_files_only\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlocal_files_only\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 431\u001b[0;31m                 \u001b[0muse_auth_token\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_auth_token\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    432\u001b[0m             )\n",
      "\u001b[0;32m~/anaconda3/envs/transformer/lib/python3.6/site-packages/transformers/file_utils.py\u001b[0m in \u001b[0;36mcached_path\u001b[0;34m(url_or_filename, cache_dir, force_download, proxies, resume_download, user_agent, extract_compressed_file, force_extract, use_auth_token, local_files_only)\u001b[0m\n\u001b[1;32m   1115\u001b[0m         \u001b[0;31m# File, but it doesn't exist.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1116\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mEnvironmentError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"file {} not found\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl_or_filename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1117\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mOSError\u001b[0m: file electranez/config.json not found",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-36-ef946ec26603>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mtokenizer2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mElectraTokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'electranez/'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mElectraForPreTraining\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'electranez/'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/transformer/lib/python3.6/site-packages/transformers/modeling_utils.py\u001b[0m in \u001b[0;36mfrom_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, *model_args, **kwargs)\u001b[0m\n\u001b[1;32m    968\u001b[0m                 \u001b[0muse_auth_token\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_auth_token\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    969\u001b[0m                 \u001b[0mrevision\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrevision\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 970\u001b[0;31m                 \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    971\u001b[0m             )\n\u001b[1;32m    972\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/transformer/lib/python3.6/site-packages/transformers/configuration_utils.py\u001b[0m in \u001b[0;36mfrom_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, **kwargs)\u001b[0m\n\u001b[1;32m    381\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    382\u001b[0m         \"\"\"\n\u001b[0;32m--> 383\u001b[0;31m         \u001b[0mconfig_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_config_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpretrained_model_name_or_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    384\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    385\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/transformer/lib/python3.6/site-packages/transformers/configuration_utils.py\u001b[0m in \u001b[0;36mget_config_dict\u001b[0;34m(cls, pretrained_model_name_or_path, **kwargs)\u001b[0m\n\u001b[1;32m    441\u001b[0m                 \u001b[0;34mf\"- or '{pretrained_model_name_or_path}' is the correct path to a directory containing a {CONFIG_NAME} file\\n\\n\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    442\u001b[0m             )\n\u001b[0;32m--> 443\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mEnvironmentError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    444\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    445\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mJSONDecodeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mOSError\u001b[0m: Can't load config for 'electranez/'. Make sure that:\n\n- 'electranez/' is a correct model identifier listed on 'https://huggingface.co/models'\n\n- or 'electranez/' is the correct path to a directory containing a config.json file\n\n"
     ]
    }
   ],
   "source": [
    "tokenizer2 = ElectraTokenizer.from_pretrained('electranez/')\n",
    "model = ElectraForPreTraining.from_pretrained('electranez/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sudden-sacramento",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "proof-sally",
   "metadata": {
    "id": "zTgWPa9Dipk2"
   },
   "outputs": [],
   "source": [
    "#@title Step 11: Defining a Data Collator\n",
    "from transformers import DataCollatorForLanguageModeling\n",
    "\n",
    "data_collator = DataCollatorForLanguageModeling(\n",
    "    tokenizer=electra_tokenizer, mlm=True, mlm_probability=0.15\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "utility-classroom",
   "metadata": {
    "id": "YpvnFFmZJD-N"
   },
   "outputs": [],
   "source": [
    "#@title Step 12: Initializing the Trainer\n",
    "from transformers import Trainer, TrainingArguments\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir='electranez',\n",
    "    overwrite_output_dir=True,\n",
    "    num_train_epochs=1,\n",
    "    per_device_train_batch_size=64,\n",
    "    save_steps=10_000,\n",
    "    save_total_limit=1,\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=generator,\n",
    "    args=training_args,\n",
    "    data_collator=data_collator,\n",
    "    train_dataset=dataset,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "organic-sculpture",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "wicked-saver",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 285
    },
    "executionInfo": {
     "elapsed": 351691,
     "status": "ok",
     "timestamp": 1611303814910,
     "user": {
      "displayName": "Karan Sonawane",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjWjX1_4b0iu2fEkjbIRKIHq-Molc5N_CnbcU75=s64",
      "userId": "05479461208077736330"
     },
     "user_tz": -330
    },
    "id": "VmaHZXzmkNtJ",
    "outputId": "998acefe-df4b-4d07-8059-d25b323587e1"
   },
   "outputs": [],
   "source": [
    "#@title Step 13: Pre-training the Model\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "integral-teddy",
   "metadata": {
    "id": "QDNgPls7_l13"
   },
   "outputs": [],
   "source": [
    "#@title Step 14: Saving the Final Model(+tokenizer + config) to disk\n",
    "trainer.save_model(\"content\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "pointed-brazilian",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 6144,
     "status": "ok",
     "timestamp": 1611304118693,
     "user": {
      "displayName": "Karan Sonawane",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjWjX1_4b0iu2fEkjbIRKIHq-Molc5N_CnbcU75=s64",
      "userId": "05479461208077736330"
     },
     "user_tz": -330
    },
    "id": "ltXgXyCbAJLY",
    "outputId": "36ddf0da-9b07-4f97-b8ad-834827e4bc25"
   },
   "outputs": [],
   "source": [
    "#@title Step 15: Language Modeling with the FillMaskPipeline\n",
    "from transformers import pipeline\n",
    "\n",
    "fill_mask = pipeline(\n",
    "    \"fill-mask\",\n",
    "    model=\"content/KantaiBERT\",\n",
    "    tokenizer=\"content/KantaiBERT\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "naked-aircraft",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
