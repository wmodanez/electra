{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "combined-berry",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install nltk\n",
    "# !pip install datasets\n",
    "!pip install ipywidgets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "liked-facility",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re, json\n",
    "\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fatal-organizer",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python -m WikiExtractor data/ptwiki-latest-pages-articles.xml.bz2 --json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "straight-population",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Punctuation list\n",
    "punctuations = re.escape('!\"#%\\'()*+,./:;<=>?@[\\\\]^_`{|}~')\n",
    "\n",
    "# ##### #\n",
    "# Regex #\n",
    "# ##### #\n",
    "re_remove_brackets = re.compile(r'\\{.*\\}')\n",
    "re_remove_html = re.compile(r'<(\\/|\\\\)?.+?>', re.UNICODE)\n",
    "re_transform_numbers = re.compile(r'\\d', re.UNICODE)\n",
    "re_transform_emails = re.compile(r'[^\\s]+@[^\\s]+', re.UNICODE)\n",
    "re_transform_url = re.compile(r'(http|https)://[^\\s]+', re.UNICODE)\n",
    "# Different quotes are used.\n",
    "re_quotes_1 = re.compile(r\"(?u)(^|\\W)[‘’′`']\", re.UNICODE)\n",
    "re_quotes_2 = re.compile(r\"(?u)[‘’`′'](\\W|$)\", re.UNICODE)\n",
    "re_quotes_3 = re.compile(r'(?u)[‘’`′“”]', re.UNICODE)\n",
    "re_dots = re.compile(r'(?<!\\.)\\.\\.(?!\\.)', re.UNICODE)\n",
    "re_punctuation = re.compile(r'([,\";:]){2},', re.UNICODE)\n",
    "re_hiphen = re.compile(r' -(?=[^\\W\\d_])', re.UNICODE)\n",
    "re_tree_dots = re.compile(u'…', re.UNICODE)\n",
    "re_changehyphen = re.compile(u'–')\n",
    "re_doublequotes_1 = re.compile(r'(\\\"\\\")')\n",
    "re_doublequotes_2 = re.compile(r'(\\'\\')')\n",
    "re_trim = re.compile(r' +', re.UNICODE)\n",
    "\n",
    "\n",
    "def clean_text(text):\n",
    "    \"\"\"Apply all regex above to a given string.\"\"\"\n",
    "#     text = text.lower()\n",
    "    text = text.replace('\\xa0', ' ')\n",
    "    text = re_tree_dots.sub('...', text)\n",
    "    text = re.sub('\\.\\.\\.', '', text)\n",
    "    text = re_remove_brackets.sub('', text)\n",
    "    text = re_changehyphen.sub('-', text)\n",
    "    text = re_remove_html.sub(' ', text)\n",
    "    text = re_transform_numbers.sub('0', text)\n",
    "    text = re_transform_url.sub('URL', text)\n",
    "    text = re_transform_emails.sub('EMAIL', text)\n",
    "    text = re_quotes_1.sub(r'\\1\"', text)\n",
    "    text = re_quotes_2.sub(r'\"\\1', text)\n",
    "    text = re_quotes_3.sub('\"', text)\n",
    "    text = re.sub('\"', '', text)\n",
    "    text = re.sub('[\\\\n]+', '\\\\n', text)\n",
    "    text = re_dots.sub('.', text)\n",
    "    text = re.sub(r'[^\\w\\s]','',text)\n",
    "    text = re_hiphen.sub(' - ', text)\n",
    "    text = re_doublequotes_1.sub('\\\"', text)\n",
    "    text = re_doublequotes_2.sub('\\'', text)\n",
    "    text = re.sub(r'\\s+', ' ', text) # Removing multiple spaces\n",
    "    text = re.sub(r\"\\s+[a-zA-Z]\\s+\", ' ', text) # Single character removal\n",
    "    text = re.sub(r'[0-9]', '', text)\n",
    "    text = re.sub(r'\\(|\\)', '', text)\n",
    "    text = re_trim.sub(' ', text)\n",
    "    return text.strip()\n",
    "\n",
    "\n",
    "# Before building the pre-training dataset, we should make sure the corpus has the following format:**\n",
    "\n",
    "# each line is a sentence\n",
    "# a blank line separates two documents\n",
    "\n",
    "\n",
    "def save_txt(text, file):\n",
    "    f = open(file, 'a')\n",
    "    f.write(text+'\\n')\n",
    "    f.close()\n",
    "    \n",
    "\n",
    "def save_full(dataframe, fraction, filename):\n",
    "    if fraction:\n",
    "        df_temp = dataframe[['id','text']].sample(frac=fraction)\n",
    "        df_temp['text'] = df_temp['text'].apply(clean_text)        \n",
    "        df_temp.to_csv('data/csv/'+filename+'.csv', sep='|', index=False)\n",
    "        df_temp['text'].apply(save_txt, file='data/txt/'+filename+'.txt')\n",
    "        return df_temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faced-bottle",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('text/wiki.json') as json_file:      \n",
    "    data = json_file.readlines()\n",
    "    # this line below may take at least 8-10 minutes of processing for 4-5 million rows. It converts all strings in list to actual json objects. \n",
    "    data = list(map(json.loads, data)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "expensive-mineral",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_wiki = pd.DataFrame(data)\n",
    "df_wiki = df_wiki.drop(['url', 'title'], axis=1)\n",
    "df_wiki['id'] = pd.to_numeric(df_wiki['id'])\n",
    "df_wiki.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "second-football",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = save_full(df_wiki, 0.1, 'texto-sm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "absent-potato",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
