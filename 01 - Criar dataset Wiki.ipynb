{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "therapeutic-fence",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Install this packs\n",
    "!pip install nltk\n",
    "\n",
    "!pip install datasets\n",
    "\n",
    "!pip install ipywidgets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "voluntary-vermont",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, re, json\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "virtual-aviation",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Download, extract and create a json file from wikipedia dump\n",
    "- wget https://dumps.wikimedia.org/ptwiki/latest/ptwiki-latest-pages-articles.xml.bz2\n",
    "- python -m WikiExtractor data/ptwiki-latest-pages-articles.xml.bz2 --json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "nonprofit-hebrew",
   "metadata": {},
   "outputs": [],
   "source": [
    "# start_time = datetime.now()\n",
    "\n",
    "# !wget https://dumps.wikimedia.org/ptwiki/latest/ptwiki-latest-pages-articles.xml.bz2 -O data/wiki.bz2\n",
    "# !python -m WikiExtractor data/wiki.bz2 --json -o data/\n",
    "\n",
    "# print('Duration: {}'.format(datetime.now() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "sudden-producer",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = 'data/'\n",
    "\n",
    "if not os.path.exists(DATA_DIR):\n",
    "    os.makedirs(DATA_DIR, mode=0o777)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "conscious-indiana",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Punctuation list\n",
    "punctuations = re.escape('!\"#%\\'()*+,./:;<=>?@[\\\\]^_`{|}~')\n",
    "\n",
    "# ##### #\n",
    "# Regex #\n",
    "# ##### #\n",
    "re_remove_brackets = re.compile(r'\\{.*\\}')\n",
    "re_remove_html = re.compile(r'<(\\/|\\\\)?.+?>', re.UNICODE)\n",
    "re_transform_numbers = re.compile(r'\\d', re.UNICODE)\n",
    "re_transform_emails = re.compile(r'[^\\s]+@[^\\s]+', re.UNICODE)\n",
    "re_transform_url = re.compile(r'(http|https)://[^\\s]+', re.UNICODE)\n",
    "# Different quotes are used.\n",
    "re_quotes_1 = re.compile(r\"(?u)(^|\\W)[‘’′`']\", re.UNICODE)\n",
    "re_quotes_2 = re.compile(r\"(?u)[‘’`′'](\\W|$)\", re.UNICODE)\n",
    "re_quotes_3 = re.compile(r'(?u)[‘’`′“”]', re.UNICODE)\n",
    "re_dots = re.compile(r'(?<!\\.)\\.\\.(?!\\.)', re.UNICODE)\n",
    "re_punctuation = re.compile(r'([,\";:]){2},', re.UNICODE)\n",
    "re_hiphen = re.compile(r' -(?=[^\\W\\d_])', re.UNICODE)\n",
    "re_tree_dots = re.compile(u'…', re.UNICODE)\n",
    "re_changehyphen = re.compile(u'–')\n",
    "re_doublequotes_1 = re.compile(r'(\\\"\\\")')\n",
    "re_doublequotes_2 = re.compile(r'(\\'\\')')\n",
    "re_trim = re.compile(r' +', re.UNICODE)\n",
    "\n",
    "\n",
    "def clean_text(text):\n",
    "    \"\"\"Apply all regex above to a given string.\"\"\"\n",
    "#     text = text.lower()\n",
    "    text = text.replace('\\xa0', ' ')\n",
    "    text = re_tree_dots.sub('...', text)\n",
    "    text = re.sub('\\.\\.\\.', '', text)\n",
    "    text = re_remove_brackets.sub('', text)\n",
    "    text = re_changehyphen.sub('-', text)\n",
    "    text = re_remove_html.sub(' ', text)\n",
    "    text = re_transform_numbers.sub('0', text)\n",
    "    text = re_transform_url.sub('URL', text)\n",
    "    text = re_transform_emails.sub('EMAIL', text)\n",
    "    text = re_quotes_1.sub(r'\\1\"', text)\n",
    "    text = re_quotes_2.sub(r'\"\\1', text)\n",
    "    text = re_quotes_3.sub('\"', text)\n",
    "    text = re.sub('\"', '', text)\n",
    "    text = re.sub('[\\\\n]+', '\\\\n', text)\n",
    "    text = re_dots.sub('.', text)\n",
    "    text = re.sub(r'[^\\w\\s]','',text)\n",
    "    text = re_hiphen.sub(' - ', text)\n",
    "    text = re_doublequotes_1.sub('\\\"', text)\n",
    "    text = re_doublequotes_2.sub('\\'', text)\n",
    "    text = re.sub(r'\\s+', ' ', text) # Removing multiple spaces\n",
    "    text = re.sub(r\"\\s+[a-zA-Z]\\s+\", ' ', text) # Single character removal\n",
    "    text = re.sub(r'[0-9]', '', text)\n",
    "    text = re.sub(r'\\(|\\)', '', text)\n",
    "    text = re_trim.sub(' ', text)\n",
    "    return text.strip()\n",
    "\n",
    "\n",
    "# Before building the pre-training dataset, we should make sure the corpus has the following format:**\n",
    "\n",
    "# each line is a sentence\n",
    "# a blank line separates two documents\n",
    "\n",
    "\n",
    "def save_txt(text, file):\n",
    "    f = open(file, 'a')\n",
    "    f.write(text+'\\n')\n",
    "    f.close()\n",
    "    \n",
    "\n",
    "def save_full(dataframe, fraction, base_dir,  filename, txt=True, csv=False):\n",
    "    df_temp = dataframe[['id','text']].sample(frac=fraction)\n",
    "    df_temp['text'] = df_temp['text'].apply(clean_text)\n",
    "       \n",
    "    if csv:\n",
    "        output = base_dir + 'csv/'\n",
    "        if not os.path.exists(output):\n",
    "            os.makedirs(output, mode=0o777)\n",
    "            \n",
    "        df_temp.to_csv(output + filename + '.csv', sep='|', index=False)\n",
    "    \n",
    "    if txt:\n",
    "        output = base_dir + 'txt/'\n",
    "        if not os.path.exists(output):\n",
    "            os.makedirs(output, mode=0o777)\n",
    "            \n",
    "        filename = output+filename+'.txt'\n",
    "        \n",
    "        if os.path.exists(filename):\n",
    "            os.remove(filename)\n",
    "            \n",
    "        df_temp['text'].apply(save_txt, file=filename)\n",
    "        \n",
    "    return df_temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "royal-education",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(DATA_DIR + 'wiki.json') as json_file:      \n",
    "    data = json_file.readlines()\n",
    "    # this line below may take at least 8-10 minutes of processing for 4-5 million rows. It converts all strings in list to actual json objects. \n",
    "    data = list(map(json.loads, data)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "rising-combining",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1058219 entries, 0 to 1058218\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count    Dtype \n",
      "---  ------  --------------    ----- \n",
      " 0   id      1058219 non-null  int64 \n",
      " 1   text    1058219 non-null  object\n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 16.1+ MB\n"
     ]
    }
   ],
   "source": [
    "df_wiki = pd.DataFrame(data)\n",
    "df_wiki = df_wiki.drop(['url', 'title'], axis=1)\n",
    "df_wiki['id'] = pd.to_numeric(df_wiki['id'])\n",
    "df_wiki.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "stunning-research",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Duration: 0:09:56.725202\n"
     ]
    }
   ],
   "source": [
    "start_time = datetime.now()\n",
    "\n",
    "df = save_full(dataframe=df_wiki, fraction=1, base_dir=DATA_DIR, filename='text')\n",
    "\n",
    "print('Duration: {}'.format(datetime.now() - start_time))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
